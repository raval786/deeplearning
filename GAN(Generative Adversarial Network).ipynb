{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../03-Convolutional-Neural-Networks/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "minist = input_data.read_data_sets(\"../03-Convolutional-Neural-Networks/MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15714a87198>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x157148df9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(minist.train.images[8].reshape(28,28),cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variable scope\n",
    "\n",
    "     variable scpope allow to have modular sections or subsets of parameter so those belonging to certatin layers that way when an architechure of layer is repeated. so when you call thisgenerator function again the same name s of those those variable can be used within each layer scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z,reuse=None): # z is the random noise that we start the generator with\n",
    "    with tf.variable_scope('gen',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=z,units= 128)\n",
    "        \n",
    "        #for leaky relu because in tensorflow 1.3 it not included but 1.4 and 1.5 are included leaky relu so we create our own leaky relu \n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs = hidden1,units = 128)\n",
    "        \n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        \n",
    "        output = tf.layers.dense(inputs=hidden2,units=784,activation=tf.nn.tanh)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def descriminator(X,reuse=None): # X is the actual data\n",
    "    with tf.variable_scope('dis',reuse=reuse):\n",
    "        hidden1 = tf.layers.dense(inputs=X,units= 128)\n",
    "        \n",
    "        #for leaky relu because in tensorflow 1.3 it not included but 1.4 and 1.5 are included leaky relu so we create our own leaky relu \n",
    "        alpha = 0.01\n",
    "        hidden1 = tf.maximum(alpha*hidden1,hidden1)\n",
    "        \n",
    "        hidden2 = tf.layers.dense(inputs = hidden1,units = 128)\n",
    "        \n",
    "        hidden2 = tf.maximum(alpha*hidden2,hidden2)\n",
    "        \n",
    "        logits = tf.layers.dense(hidden2,units=1)\n",
    "        output = tf.sigmoid(logits)\n",
    "        \n",
    "        return output,logits\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "realimage = tf.placeholder(tf.float32,shape = [None,784]) # None for batch size that we later define and 784 is multiplication of 28*28 pixles\n",
    "z = tf.placeholder(tf.float32,shape = [None,100]) # 100 because we want to generate 100 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = generator(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_output_real , D_logits_real = descriminator(realimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_output_fake , D_logits_fake = descriminator(G,reuse = True) # reuse = True beacause we use the descriminator twise so if we don't use variable scpe we get error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_func(logits_in,lables_in):\n",
    "    return tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(labels = lables_in, logits = logits_in))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_real_loss = loss_func(D_logits_real,tf.ones_like(D_logits_real) *0.9)\n",
    "D_fake_loss = loss_func(D_logits_fake,tf.zeros_like(D_logits_real))\n",
    "# ,tf.ones_like(D_logits_real) with this we declare all the real lables are set 1  or say true\n",
    "# ,tf.zeros_like(D_logits_real) with tis we decalare all the fake lables are 0 or false\n",
    "# tf.one() take several parameter and tf.ones_like only take shpae so we take tf.ones_like\n",
    "\n",
    "#to make descriminator generalize we apply smoothing,so this hepls descriminator generalize better. it basically maeans that we reduce the lable a bit from being perfect from\n",
    "#1.0 to being smothing 0.9 so we do *0.9 to apply smoothing factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_loss = D_real_loss + D_fake_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "G_loss = loss_func(D_logits_fake,tf.ones_like(D_logits_fake))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvars = tf.trainable_variables() # Returns all variables created with `trainable=True`., function returns the contents of that collection.\n",
    "\n",
    "d_vars = [var for var in tvars if 'dis' in var.name] # for every variable in trainable variable dis(descriminator) in it's name. \n",
    "g_vars = [var for var in tvars if 'gen' in var.name]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "D_trainer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(D_loss, var_list=d_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_trainer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(G_loss, var_list=g_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dis/dense/kernel:0' shape=(784, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_1/kernel:0' shape=(128, 128) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_1/bias:0' shape=(128,) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_2/kernel:0' shape=(128, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'dis/dense_2/bias:0' shape=(1,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_vars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "samples = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently on Epoch 1 of 30 total...\n",
      "Currently on Epoch 2 of 30 total...\n",
      "Currently on Epoch 3 of 30 total...\n",
      "Currently on Epoch 4 of 30 total...\n",
      "Currently on Epoch 5 of 30 total...\n",
      "Currently on Epoch 6 of 30 total...\n",
      "Currently on Epoch 7 of 30 total...\n",
      "Currently on Epoch 8 of 30 total...\n",
      "Currently on Epoch 9 of 30 total...\n",
      "Currently on Epoch 10 of 30 total...\n",
      "Currently on Epoch 11 of 30 total...\n",
      "Currently on Epoch 12 of 30 total...\n",
      "Currently on Epoch 13 of 30 total...\n",
      "Currently on Epoch 14 of 30 total...\n",
      "Currently on Epoch 15 of 30 total...\n",
      "Currently on Epoch 16 of 30 total...\n",
      "Currently on Epoch 17 of 30 total...\n",
      "Currently on Epoch 18 of 30 total...\n",
      "Currently on Epoch 19 of 30 total...\n",
      "Currently on Epoch 20 of 30 total...\n",
      "Currently on Epoch 21 of 30 total...\n",
      "Currently on Epoch 22 of 30 total...\n",
      "Currently on Epoch 23 of 30 total...\n",
      "Currently on Epoch 24 of 30 total...\n",
      "Currently on Epoch 25 of 30 total...\n",
      "Currently on Epoch 26 of 30 total...\n",
      "Currently on Epoch 27 of 30 total...\n",
      "Currently on Epoch 28 of 30 total...\n",
      "Currently on Epoch 29 of 30 total...\n",
      "Currently on Epoch 30 of 30 total...\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(init)\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        \n",
    "        num_batches = minist.train.num_examples // batch_size # gives the whole number.  // indicates classic division\n",
    "        \n",
    "        for i in range(num_batches):\n",
    "            batch = minist.train.next_batch(batch_size)\n",
    "            \n",
    "            # Get images, reshape and rescale to pass to D\n",
    "            batch_images = batch[0].reshape((batch_size, 784)) # reacaling the images to fit in to network\n",
    "            batch_images = batch_images *2 - 1 # for linear transoformation for tanh\n",
    "            \n",
    "            # Z (random latent noise data for Generator)\n",
    "            # -1 to 1 because of tanh activation\n",
    "            batch_z = np.random.uniform(-1,1,size=(batch_size,100))\n",
    "            \n",
    "            _ = sess.run(D_trainer,feed_dict={realimage:batch_images, z:batch_z}) # _ = because we don't want to store the result we just want to run it\n",
    "            _ = sess.run(G_trainer,feed_dict={z:batch_z})\n",
    "            \n",
    "        print(\"Currently on Epoch {} of {} total...\".format(e+1, epochs))\n",
    "        \n",
    "        sample_z = np.random.uniform(-1,1,size=(1,100)) # in size=(1,100) 1 for we want 1 sample and 100 is our batch_size\n",
    "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        \n",
    "        samples.append(gen_sample)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x15715765668>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niV+IRJH4hUgUiV+IRJH4hUgUiV+IRPl/hAs485kXAvMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x15715489438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(samples[3].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the 500 epoch train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from 06-Generative-Adversarial-Networks/models/500_epoch_model.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list=g_vars)\n",
    "\n",
    "new_samples = []\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    saver.restore(sess,'06-Generative-Adversarial-Networks/models/500_epoch_model.ckpt')\n",
    "    \n",
    "    for x in range(5):\n",
    "        sample_z = np.random.uniform(-1,1,size=(1,100))\n",
    "        gen_sample = sess.run(generator(z,reuse=True),feed_dict={z:sample_z})\n",
    "        \n",
    "        new_samples.append(gen_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(new_samples[3].reshape(28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
